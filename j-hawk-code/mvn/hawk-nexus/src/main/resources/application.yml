server:
  port: 9000

topomind:
  url: http://127.0.0.1:8000
  service-name: hawk_runtime
  base-url: http://127.0.0.1:9000
  llm-backend: cohere

  # Default execution model (change this to switch models)
  execution-model: command-a-03-2025

  # All available Groq models
  models:
    - allam-2-7b
    - groq/compound-mini
    - whisper-large-v3
    - llama-3.3-70b-versatile
    - openai/gpt-oss-120b
    - meta-llama/llama-prompt-guard-2-86m
    - groq/compound
    - whisper-large-v3-turbo
    - meta-llama/llama-4-maverick-17b-128e-instruct
    - canopylabs/orpheus-v1-english
    - moonshotai/kimi-k2-instruct
    - llama-3.1-8b-instant
    - canopylabs/orpheus-arabic-saudi
    - meta-llama/llama-guard-4-12b
    - openai/gpt-oss-safeguard-20b
    - meta-llama/llama-prompt-guard-2-22m
    - moonshotai/kimi-k2-instruct-0905
    - qwen/qwen3-32b
    - openai/gpt-oss-20b
    - meta-llama/llama-4-scout-17b-16e-instruct
